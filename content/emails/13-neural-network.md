# SpeakNerd Weekly #13: Neural Network

**Subject line:** We built a brain. Kind of. Here's how.

---

Hey â€” Steve here.

Last week we covered **Deep Learning**. This week, let's talk about something you've probably heard but maybe never fully understood.

## This Week's Term: Neural Network

**The quick version:** A computer system loosely inspired by how brain cells connect. It's how AI learns patterns. Don't worry â€” it's not actually a brain.

**The deeper version:**

Your brain has about 86 billion neurons connected by trillions of synapses. When you learn something â€” like recognizing your mom's face or catching a ball â€” your neurons form patterns. Do something enough times, and the pattern gets strong.

A neural network is a computer program that borrows this idea. It has artificial "neurons" arranged in layers. Data goes in one side, passes through layers of neurons that each do a tiny calculation, and a result comes out the other side. The magic is that the network can learn by adjusting the connections between neurons until it gets good at whatever task you give it.

Show it 10,000 pictures of cats and 10,000 pictures of dogs, and it'll learn to tell the difference. Show it millions of sentences, and it'll learn to write like a human. That's how LLMs work at their core â€” they're really big neural networks trained on really big datasets.

## Why This Matters

Because neural networks are the foundation of basically all modern AI. When someone says "machine learning" or "deep learning" or "AI model," they're almost always talking about some flavor of neural network. Understanding this concept is like understanding that cars have engines â€” you don't need to build one, but it helps to know it's there.

## Try It Yourself (2 minutes)

Draw something on quickdraw.withgoogle.com â€” Google's neural network tries to guess what you're drawing in real time.

## Go Deeper

- Search for "Neural Network explained simply" â€” you'll find great visual guides
- ðŸ”— [Read the full SpeakNerd term page](https://speaknerd.ai/terms/neural-network)

## The Nerd Corner

Neural networks consist of interconnected nodes organized in layers (input, hidden, output). Each connection has a weight adjusted during training via backpropagation and gradient descent. Activation functions (ReLU, sigmoid, softmax) introduce non-linearity. Modern architectures include CNNs (images), RNNs/LSTMs (sequences), and Transformers (attention-based, used in LLMs).

---

*Next week: **Training Data** â€” we'll break down what it means and why you should care.*

*â€” Steve*

*P.S. Know someone who'd find this useful? Forward this email. They can [sign up here](https://speaknerd.ai).*
