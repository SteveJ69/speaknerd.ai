# SpeakNerd Weekly #30: Bias

**Subject line:** When AI inherits our worst habits

---

Hey â€” Steve here.

Last week we covered **Text-to-Image**. This week, let's talk about something you've probably heard but maybe never fully understood.

## This Week's Term: Bias

**The quick version:** AI learns from human data, and humans are biased. So AI picks up those biases too. If you only show it photos of male CEOs, it assumes all CEOs are male.

**The deeper version:**

Here's an uncomfortable truth: AI is basically a mirror. It reflects whatever it was trained on â€” including all the biases, stereotypes, and unfairness baked into that data.

If an AI was trained on decades of hiring data where men were hired more often for engineering roles, it might learn that "engineer = male" and start penalizing female applicants. Not because anyone told it to be sexist â€” but because the historical data WAS sexist, and the AI learned the pattern. Amazon actually built a hiring AI that did exactly this. They had to scrap it.

It goes beyond gender. AI can be biased about race, age, geography, language, disability, and more. Facial recognition systems have been shown to work great on white faces and terribly on darker skin tones â€” because the training data was mostly white faces. The AI wasn't racist on purpose. It just never learned to see everyone equally.

## Why This Matters

Because biased AI makes real decisions about real people. Loan approvals, job screenings, medical diagnoses, criminal sentencing â€” AI is being used in all of these. If you're ever on the receiving end of an AI decision (and you will be), understanding bias helps you question results that don't seem right instead of blindly accepting the computer's answer.

## Try It Yourself (2 minutes)

Ask an AI to "draw a CEO" or "describe a typical nurse." Notice the assumptions about gender and ethnicity â€” those came from biased training data.

## Go Deeper

- Search for "Bias explained simply" â€” you'll find great visual guides
- ðŸ”— [Read the full SpeakNerd term page](https://speaknerd.ai/terms/bias)

## The Nerd Corner

AI bias arises from multiple sources: training data bias (unrepresentative or historically skewed datasets), algorithmic bias (model architecture choices that amplify patterns), and deployment bias (using models in contexts they weren't designed for). Mitigation strategies include diverse and representative data collection, fairness-aware training objectives, bias auditing tools (AIF360, Fairlearn), red-teaming, and human-in-the-loop review for high-stakes decisions.

---

*Next week: **Alignment** â€” we'll break down what it means and why you should care.*

*â€” Steve*

*P.S. Know someone who'd find this useful? Forward this email. They can [sign up here](https://speaknerd.ai).*
