---
title: "Fine-tuning"
subtitle: "Teaching AI to specialize"
category: "ai-basics"
difficulty: "beginner"
tldr: "Taking a general AI and training it to be an expert at one specific thing. Like teaching a general practitioner to be a heart surgeon."
related: ["llm", "gpt", "rag"]
---

## The Plain English Version

Imagine a doctor who just graduated medical school. They know a little about everything — bones, hearts, skin, brains. They're smart, but they're not an expert in anything specific. Now imagine that doctor spends two years doing nothing but heart surgery. After that, they're a heart specialist.

That's fine-tuning. You take a general AI that knows a little about everything (like ChatGPT) and train it on a specific set of data so it becomes really good at one thing. Want an AI that writes like your company? Fine-tune it on your company's writing. Want one that knows everything about tax law? Fine-tune it on tax documents.

The original AI already has the foundation — it knows language, it knows how to reason, it knows how to write. Fine-tuning just sharpens it in one direction.

## Why Should You Care?

Because this is how businesses are making AI actually useful for specific tasks. A generic AI gives generic answers. A fine-tuned AI gives answers that sound like they came from an expert in your field. If you ever build something with AI, fine-tuning might be how you make it stand out from everyone else using the same generic tools.

## The Nerd Version (if you dare)

Fine-tuning involves additional training of a pre-trained model on a domain-specific dataset. It adjusts the model's weights to optimize for a particular task while retaining general knowledge. Methods include full fine-tuning (expensive), LoRA (Low-Rank Adaptation), and QLoRA. It's distinct from RAG, which adds knowledge at inference time rather than training time.
