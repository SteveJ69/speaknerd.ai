---
title: "Prompt"
subtitle: "The thing you type into AI"
category: "ai-basics"
difficulty: "beginner"
tldr: "The instruction you give an AI. Better prompts = better answers. It's like asking good questions at a bar."
related: ["llm", "token", "fine-tuning"]
---

## The Plain English Version

A prompt is just whatever you type into an AI. That's it. When you ask ChatGPT "What should I make for dinner?" — that's a prompt.

But here's where it gets interesting: the *way* you ask completely changes what you get back. Asking "What should I make for dinner?" gets you a generic answer. Asking "I have chicken, rice, and bell peppers. What's a quick dinner I can make in 30 minutes that my picky kids will eat?" gets you something actually useful.

Think of it like ordering at a restaurant. "Give me food" will get you something. "I'd like the grilled salmon, medium rare, with the garlic mashed potatoes and a side of the house vinaigrette" gets you exactly what you want.

That's all prompt engineering is — learning to ask AI better questions.

## Why Should You Care?

Because the difference between a useless AI response and a mind-blowing one is usually just how you asked. People who write good prompts get 10x more out of the same tools as people who don't. It's the single most valuable skill in AI right now, and it costs nothing to learn.

## The Nerd Version (if you dare)

A prompt is the input text provided to a language model that conditions its output generation. In the context of transformer models, the prompt tokens are processed through the attention mechanism to establish context. System prompts, few-shot examples, and chain-of-thought reasoning are advanced prompting techniques that significantly improve output quality.
